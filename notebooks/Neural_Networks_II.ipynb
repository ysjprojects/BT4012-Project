{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a468951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f144110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "train_data = pd.read_csv(\"../data/5_train_dataset.csv\")\n",
    "X_train = train_data.drop('is_fraud', axis=1)\n",
    "y_train = train_data['is_fraud']\n",
    "\n",
    "test_data = pd.read_csv(\"../data/4_test_dataset.csv\")\n",
    "X_test = test_data.drop('is_fraud', axis=1)\n",
    "y_test = test_data['is_fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693df62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_FEATURES = len(X_train.columns)\n",
    "N_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cccac6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary encoding of labels\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d048951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a22ddf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wide(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(N_FEATURES, 180)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(180, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n",
    "\n",
    "class Deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(N_FEATURES, 60)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(60, 60)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(60, 60)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(60, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abdbc421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4141\n",
      "8701\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare model sizes\n",
    "model1 = Wide()\n",
    "model2 = Deep()\n",
    "print(sum([x.reshape(-1).shape[0] for x in model1.parameters()]))\n",
    "print(sum([x.reshape(-1).shape[0] for x in model2.parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81af28fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper function to train one model\n",
    "def model_train(model, X_train, y_train, X_val, y_val):\n",
    "    # loss function and optimizer\n",
    "    loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    n_epochs = 300   # number of epochs to run\n",
    "    batch_size = 10  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    "\n",
    "    # Hold the best model\n",
    "    best_acc = - np.inf   # init to negative infinity\n",
    "    best_weights = None\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        acc = (y_pred.round() == y_val).float().mean()\n",
    "        acc = float(acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "    # restore model and return best accuracy\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afba143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (wide): 0.82\n",
      "Accuracy (wide): 0.85\n",
      "Accuracy (wide): 0.83\n",
      "Accuracy (wide): 0.85\n",
      "Accuracy (wide): 0.84\n",
      "Accuracy (deep): 0.90\n",
      "Accuracy (deep): 0.85\n",
      "Accuracy (deep): 0.88\n",
      "Accuracy (deep): 0.88\n",
      "Accuracy (deep): 0.84\n",
      "Wide: 83.85% (+/- 1.01%)\n",
      "Deep: 87.11% (+/- 2.33%)\n",
      "Retrain a deep model\n"
     ]
    }
   ],
   "source": [
    "# define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cv_scores_wide = []\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    # create model, train, and get accuracy\n",
    "    model = Wide()\n",
    "    acc = model_train(model, X_train[train], y_train[train], X_train[test], y_train[test])\n",
    "    print(\"Accuracy (wide): %.2f\" % acc)\n",
    "    cv_scores_wide.append(acc)\n",
    "cv_scores_deep = []\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    # create model, train, and get accuracy\n",
    "    model = Deep()\n",
    "    acc = model_train(model, X_train[train], y_train[train], X_train[test], y_train[test])\n",
    "    print(\"Accuracy (deep): %.2f\" % acc)\n",
    "    cv_scores_deep.append(acc)\n",
    "\n",
    "# evaluate the model\n",
    "wide_acc = np.mean(cv_scores_wide)\n",
    "wide_std = np.std(cv_scores_wide)\n",
    "deep_acc = np.mean(cv_scores_deep)\n",
    "deep_std = np.std(cv_scores_deep)\n",
    "print(\"Wide: %.2f%% (+/- %.2f%%)\" % (wide_acc*100, wide_std*100))\n",
    "print(\"Deep: %.2f%% (+/- %.2f%%)\" % (deep_acc*100, deep_std*100))\n",
    "\n",
    "# rebuild model with full set of training data\n",
    "if wide_acc > deep_acc:\n",
    "    print(\"Retrain a wide model\")\n",
    "    model = Wide()\n",
    "else:\n",
    "    print(\"Retrain a deep model\")\n",
    "    model = Deep()\n",
    "acc = model_train(model, X_train, y_train, X_test, y_test)\n",
    "print(f\"Final model accuracy: {acc*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
